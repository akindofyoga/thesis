@CONFERENCE{ImageNet_VSS09,
        AUTHOR = {Deng, J. and Li, K. and Do, M. and Su, H. and Fei-Fei, L.},
        TITLE = {{Construction and Analysis of a Large Scale Image Ontology}},
        ORGANIZATION = {Vision Sciences Society},
        YEAR = {2009},
        BIBSOURCE = "http://www.image-net.org/papers/ImageNet_VSS2009.bib"}

@inproceedings{KrauseStarkDengFei-Fei_3DRR2013,
  title = {3D Object Representations for Fine-Grained Categorization},
  booktitle = {4th International IEEE Workshop on  3D Representation and Recognition (3dRR-13)},
  year = {2013},
  address = {Sydney, Australia},
  author = {Jonathan Krause and Michael Stark and Jia Deng and Li Fei-Fei}
}

@inproceedings{collaboration,
author = {Johnson, Steven and Gibson, Madeleine and Mutlu, Bilge},
title = {Handheld or Handsfree? Remote Collaboration via Lightweight Head-Mounted Displays and Handheld Devices},
year = {2015},
isbn = {9781450329224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2675133.2675176},
doi = {10.1145/2675133.2675176},
abstract = {Emerging wearable and mobile communication technologies, such as lightweight head-mounted
displays (HMDs) and handheld devices, promise support for everyday remote collaboration.
Despite their potential for widespread use, their effectiveness as collaborative tools
is unknown, particularly in physical tasks involving mobility. To better understand
their impact on collaborative behaviors, perceptions, and performance, we conducted
a two-by-two (technology type: HMD vs. tablet computer; task setting: static vs. dynamic)
between-subjects study where participants (n=66) remotely collaborated as ``helper'
and ``worker' pairs in the construction of a physical object. Our results showed that,
in the dynamic task, HMD use enabled helpers to offer more frequent directing commands
and more proactive assistance, resulting in marginally faster task completion. In
the static task, while tablet use helped convey subtle visual information, helpers
and workers had conflicting perceptions of how the two technologies contributed to
their success. Our findings offer strong design and research implications, underlining
the importance of a consistent view of the shared workspace and the differential support
collaborators with different roles receive from technologies.},
booktitle = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work and Social Computing},
pages = {1825–1836},
numpages = {12},
keywords = {tablet computers, computer-supported cooperative work, head-mounted displays (hmds), videoconferencing, remote collaboration, wearable computing, handheld devices},
location = {Vancouver, BC, Canada},
series = {CSCW '15}
}

@inproceedings{robotic_arm,
author = {Lafreniere, Benjamin and Grossman, Tovi and Anderson, Fraser and Matejka, Justin and Kerrick, Heather and Nagy, Danil and Vasey, Lauren and Atherton, Evan and Beirne, Nicholas and Coelho, Marcelo H. and Cote, Nicholas and Li, Steven and Nogueira, Andy and Nguyen, Long and Schwinn, Tobias and Stoddart, James and Thomasson, David and Wang, Ray and White, Thomas and Benjamin, David and Conti, Maurice and Menges, Achim and Fitzmaurice, George},
title = {Crowdsourced Fabrication},
year = {2016},
isbn = {9781450341899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2984511.2984553},
doi = {10.1145/2984511.2984553},
abstract = {In recent years, extensive research in the HCI literature has explored interactive
techniques for digital fabrication. However, little attention in this body of work
has examined how to involve and guide human workers in fabricating larger-scale structures.
We propose a novel model of crowdsourced fabrication, in which a large number of workers
and volunteers are guided through the process of building a pre-designed structure.
The process is facilitated by an intelligent construction space capable of guiding
individual workers and coordinating the overall build process. More specifically,
we explore the use of smartwatches, indoor location sensing, and instrumented construction
materials to provide real-time guidance to workers, coordinated by a foreman engine
that manages the overall build process. We report on a three day deployment of our
system to construct a 12-tall bamboo pavilion with assistance from more than one hundred
volunteer workers, and reflect on observations and feedback collected during the exhibit.},
booktitle = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
pages = {15–28},
numpages = {14},
keywords = {crowdsourcing, fabrication, iot, wearables},
location = {Tokyo, Japan},
series = {UIST '16}
}

@InProceedings{smartwatch,
author="Aehnelt, Mario
and Urban, Bodo",
editor="Nah, Fiona Fui-Hoon",
title="Follow-Me: Smartwatch Assistance on the Shop Floor",
booktitle="HCI in Business",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="279--287",
abstract="The growing complexity of manufacturing calls for new approaches to support the human workforce with situation-aware information and tools which in consequence ease the process of understanding and applying work related knowledge. With this paper we introduce a theoretical model for a systematic information transfer between assistance system and worker. It defines assistance objectives and reviews the role of artifacts during the assistance process focusing on the cognitive aspects of work. Our approach was implemented using smartwatches for application in industrial assembly environments extending the Plant@Hand manufacturing performance support system.",
isbn="978-3-319-07293-7"
}

@inproceedings{smartwatch2,
author = {Bader, Sebastian and Aehnelt, Mario},
title = {Tracking Assembly Processes and Providing Assistance in Smart Factories},
year = {2014},
isbn = {9789897580154},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0004822701610168},
doi = {10.5220/0004822701610168},
abstract = {Tracking assembly processes is a necessary prerequisite to provide assistance in smart
factories. In this paper, we show how to track the construction of complex components.
For this we employ formal task models as background knowledge and simple sensors like
RFIDs. The background knowledge is converted into a probabilistic model that actually
tracks the process. As a result, we are able to provide assistance in smart factories.
We discuss the performance of the approach, as well as potential applications.},
booktitle = {Proceedings of the 6th International Conference on Agents and Artificial Intelligence - Volume 1},
pages = {161–168},
numpages = {8},
keywords = {Assembly Tracking, Assistance, Smart Factory},
location = {ESEO, Angers, Loire Valley, France},
series = {ICAART 2014}
}

@inproceedings{kinect,
author = {Gupta, Ankit and Fox, Dieter and Curless, Brian and Cohen, Michael},
title = {DuploTrack: A Real-Time System for Authoring and Guiding Duplo Block Assembly},
year = {2012},
isbn = {9781450315807},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2380116.2380167},
doi = {10.1145/2380116.2380167},
abstract = {We demonstrate a realtime system which infers and tracks the assembly process of a
snap-together block model using a Kinect® sensor. The inference enables us to build
a virtual replica of the model at every step. Tracking enables us to provide context
specific visual feedback on a screen by augmenting the rendered virtual model aligned
with the physical model. The system allows users to author a new model and uses the
inferred assembly process to guide its recreation by others. We propose a novel way
of assembly guidance where the next block to be added is rendered in blinking mode
with the tracked virtual model on screen. The system is also able to detect any mistakes
made and helps correct them by providing appropriate feedback. We focus on assemblies
of Duplo® blocks.We discuss the shortcomings of existing methods of guidance - static
figures or recorded videos - and demonstrate how our method avoids those shortcomings.
We also report on a user study to compare our system with standard figure-based guidance
methods found in user manuals. The results of the user study suggest that our method
is able to aid users' structural perception of the model better, leads to fewer assembly
errors, and reduces model construction time.},
booktitle = {Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology},
pages = {389–402},
numpages = {14},
keywords = {assembly tasks, augmented reality, depth camera, active visual feedback, tracking, virtual reality},
location = {Cambridge, Massachusetts, USA},
series = {UIST '12}
}

@InProceedings{sensors,
author="Antifakos, Stavros
and Michahelles, Florian
and Schiele, Bernt",
editor="Borriello, Gaetano
and Holmquist, Lars Erik",
title="Proactive Instructions for Furniture Assembly",
booktitle="UbiComp 2002: Ubiquitous Computing",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="351--360",
abstract="Tennenhouse [1] coined the term proactive computing where humans get out of the interaction loop and may be serviced specifically according to their needs and current situation. In this paper we propose a framework for proactive guidance which aims to overcome limitations of today's printed instructions. By attaching computing devices and multiple sensors onto different parts of the assembly the system can recognize the actions of the user and determine the current state of the assembly. The system can suggest the next most appropriate action at any point in time. In an experimental case study with the IKEA PAX wardrobe we show the feasibility of the proposed approach. At the end important issues are discussed and future directions are outlined.",
isbn="978-3-540-45809-8"
}

@InProceedings{webuild,
author = {Fraser, C. Ailie and Grossman, Tovi and Fitzmaurice, George},
title = {WeBuild: Automatically Distributing Assembly Tasks Among Collocated Workers to Improve Coordination},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026036},
abstract = {Physical construction and assembly tasks are often carried out by groups of collocated
workers, and they can be difficult to coordinate. Group members must spend time deciding
how to split up the task, how to assign subtasks to each other, and in what order
subtasks should be completed. Informed by an observational study examining group coordination
challenges, we built a task distribution system called WeBuild. Our custom algorithm
dynamically assigns subtasks to workers in a group, taking into account factors such
as the dependencies between subtasks and the skills of each group member. Each worker
views personalized step-by-step instructions on a mobile phone, while a dashboard
visualizes the entire process. An initial study found that WeBuild reduced the start-up
time needed to coordinate and begin a task, and provides direction for future research
to build on toward improving group efficiency and coordination for complex tasks.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1817–1830},
numpages = {14}
}

@article{synthetic,
  author    = {Stefan Hinterstoisser and
               Olivier Pauly and
               Hauke Heibel and
               Martina Marek and
               Martin Bokeloh},
  title     = {An Annotation Saved is an Annotation Earned: Using Fully Synthetic
               Training for Object Instance Detection},
  journal   = {CoRR},
  volume    = {abs/1902.09967},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.09967},
  archivePrefix = {arXiv},
  eprint    = {1902.09967},
  timestamp = {Tue, 21 May 2019 18:03:39 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-09967.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{shaping,
author = {Hu, Wenlu and Amos, Brandon and Chen, Zhuo and Ha, Kiryong and Richter, Wolfgang and Pillai, Padmanabhan and Gilbert, Benjamin and Harkes, Jan and Satyanarayanan, Mahadev},
title = {The Case for Offload Shaping},
year = {2015},
isbn = {9781450333917},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2699343.2699351},
doi = {10.1145/2699343.2699351},
abstract = {When offloading computation from a mobile device, we show that it can pay to perform
additional on-device work in order to reduce the offloading workload. We call this
offload shaping, and demonstrate its application at many different levels of abstraction
using a variety of techniques. We show that offload shaping can produce significant
reduction in resource demand, with little loss of application-level fidelity.},
booktitle = {Proceedings of the 16th International Workshop on Mobile Computing Systems and Applications},
pages = {51–56},
numpages = {6},
keywords = {mobile computing, cloud computing, energy-efficient computing, wireless networks, cyber foraging, wearable computing, early discard, wifi, google glass, cloud offload, cloudlet},
location = {Santa Fe, New Mexico, USA},
series = {HotMobile '15}
}

@article{coco,
  author    = {Tsung{-}Yi Lin and
               Michael Maire and
               Serge J. Belongie and
               Lubomir D. Bourdev and
               Ross B. Girshick and
               James Hays and
               Pietro Perona and
               Deva Ramanan and
               Piotr Doll{\'{a}}r and
               C. Lawrence Zitnick},
  title     = {Microsoft {COCO:} Common Objects in Context},
  journal   = {CoRR},
  volume    = {abs/1405.0312},
  year      = {2014},
  url       = {http://arxiv.org/abs/1405.0312},
  archivePrefix = {arXiv},
  eprint    = {1405.0312},
  timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LinMBHPRDZ14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{latency,
    doi = {10.1371/journal.pone.0248690},
    author = {Olguín Muñoz, Manuel AND Klatzky, Roberta AND Wang, Junjue AND Pillai, Padmanabhan AND Satyanarayanan, Mahadev AND Gross, James},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Impact of delayed response on wearable cognitive assistance},
    year = {2021},
    month = {03},
    volume = {16},
    url = {https://doi.org/10.1371/journal.pone.0248690},
    pages = {1-25},
    abstract = {Wearable cognitive assistants (WCA) are anticipated to become a widely-used application class, in conjunction with emerging network infrastructures like 5G that incorporate edge computing capabilities. While prototypical studies of such applications exist today, the relationship between infrastructure service provisioning and its implication for WCA usability is largely unexplored despite the relevance that these applications have for future networks. This paper presents an experimental study assessing how WCA users react to varying end-to-end delays induced by the application pipeline or infrastructure. Participants interacted directly with an instrumented task-guidance WCA as delays were introduced into the system in a controllable fashion. System and task state were tracked in real time, and biometric data from wearable sensors on the participants were recorded. Our results show that periods of extended system delay cause users to correspondingly (and substantially) slow down in their guided task execution, an effect that persists for a time after the system returns to a more responsive state. Furthermore, the slow-down in task execution is correlated with a personality trait, neuroticism, associated with intolerance for time delays. We show that our results implicate impaired cognitive planning, as contrasted with resource depletion or emotional arousal, as the reason for slowed user task executions under system delay. The findings have several implications for the design and operation of WCA applications as well as computational and communication infrastructure, and additionally for the development of performance analysis tools for WCA.},
    number = {3}
}

@misc{TPOD,
  title = {OpenTPOD},
  howpublished = {\url{https://github.com/cmusatyalab/OpenTPOD}}
}

@misc{workflow,
  title = {OpenWorkflow},
  howpublished = {\url{https://github.com/cmusatyalab/OpenWorkflow}}
}

@misc{lamp,
  title = {Lamp Assistant},
  howpublished = {\url{https://github.com/cmusatyalab/gabriel-ikea}}
}

@misc{sandwich,
  title = {Sandwich Assistant},
  howpublished = {\url{https://github.com/cmusatyalab/gabriel-sandwich}}
}

@misc{lego,
  title = {Lego Assistant},
  howpublished = {\url{https://github.com/cmusatyalab/gabriel-lego}}
}

@INPROCEEDINGS{satya14,
  author={Satyanarayanan, Mahadev and Chen, Zhuo and Ha, Kiryong and Hu, Wenlu and Richter, Wolfgang and Pillai, Padmanabhan},
  booktitle={6th International Conference on Mobile Computing, Applications and Services},
  title={Cloudlets: at the leading edge of mobile-cloud convergence},
  year={2014},
  volume={},
  number={},
  pages={1-9},
  doi={10.4108/icst.mobicase.2014.257757}}

@misc{dynamics365,
  title = {Dynamics 365 Remote Assist},
  howpublished = {\url{https://dynamics.microsoft.com/en-us/mixed-reality/remote-assist/}}
}

@misc{webex,
  title = {Webex Expert on Demand},
  howpublished = {\url{https://www.webex.com/industries/frontline.html}}
}

@misc{xpert,
  title = {AMA XpertEye},
  howpublished = {\url{https://www.amaxperteye.com/}}
}

@misc{vieaura,
  title = {Vieaura},
  howpublished = {\url{https://vieaura.com/}}
}

@misc{zoom,
  title = {Zoom Client SDKs},
  howpublished = {\url{https://marketplace.zoom.us/docs/sdk/native-sdks/}}
}

@InProceedings{Li_2018_CVPR,
           author = {Li, Peihua and Xie, Jiangtao and Wang, Qilong and Gao, Zilin},
           title = {Towards Faster Training of Global Covariance Pooling Networks by Iterative Matrix Square Root Normalization},
           booktitle = { IEEE Int. Conf. on Computer Vision and Pattern Recognition (CVPR)},
           month = {June},
           year = {2018}
}

@misc{websocket,
  title = {The WebSocket Protocol},
  howpublished = {\url{https://tools.ietf.org/html/rfc6455}}
}

@misc{gabriel_github,
  title = {The Gabriel framework for wearable cognitive assistance using
  cloudlets},
  howpublished = {\url{https://github.com/cmusatyalab/gabriel}}
}

@article{opencv_library,
    author = {Bradski, G.},
    citeulike-article-id = {2236121},
    journal = {Dr. Dobb's Journal of Software Tools},
    keywords = {bibtex-import},
    posted-at = {2008-01-15 19:21:54},
    priority = {4},
    title = {{The OpenCV Library}},
    year = {2000}
}

@misc{camerax,
  title = {CameraX overview},
  howpublished = {\url{https://developer.android.com/training/camerax}}
}

@misc{gabriel_server,
  title = {Gabriel Server},
  howpublished = {\url{https://pypi.org/project/gabriel-server/}}
}

@misc{gabriel_python_client,
  title = {Gabriel Python Client},
  howpublished = {\url{https://pypi.org/project/gabriel-client/}}
}

@misc{gabriel_android_client,
  title = {Gabriel Android Client},
  howpublished = {\url{https://repo1.maven.org/maven2/edu/cmu/cs/gabriel/}}
}

@misc{zmq,
  title = {ZeroMQ},
  howpublished = {\url{https://zeromq.org/}}
}

@article{Satya2017,
 author = "Mahadev Satyanarayanan",
 title = "{The Emergence of Edge Computing}",
 journal = "{IEEE Computer}",
 volume = "50",
 number = "1",
 year = "2017"
}

@conference{visapp19,
author={Julien Miranda. and Stanislas Larnier. and Ariane Herbulot. and Michel Devy.},
title={UAV-based Inspection of Airplane Exterior Screws with Computer Vision},
booktitle={Proceedings of the 14th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications - Volume 4: VISAPP,},
year={2019},
pages={421-427},
publisher={SciTePress},
organization={INSTICC},
doi={10.5220/0007571304210427},
isbn={978-989-758-354-4},
issn={2184-4321},
}

@article{FOO2021666,
title = {Screw detection for disassembly of electronic waste using reasoning and re-training of a deep learning model},
journal = {Procedia CIRP},
volume = {98},
pages = {666-671},
year = {2021},
note = {The 28th CIRP Conference on Life Cycle Engineering, March 10 – 12, 2021, Jaipur, India},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.01.172},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121002031},
author = {Gwendolyn Foo and Sami Kara and Maurice Pagnucco},
keywords = {disassembly automation, computer vision, screw detection, ontology, logical reasoning, LCD monitors},
abstract = {Growing populations, increasing standards of living, and reliance on advancing technologies are resulting in an emerging abundance of electronic waste. Automating disassembly of these electronic products is a vital part of improving end-of-life product treatment where hazardous chemicals and materials are present. Furthermore, non-destructive disassembly is ideal to preserve the embodied energy in components from manufacturing. This requires the removal, and hence detection, of fasteners like screws in a disassembly environment. Crosshead screws are a common fastener type used in LCD monitors. This paper proposes a method of screw detection for disassembly and presents results of detection of crosshead screws on components of various models of LCD monitors in a disassembly cell. The system first applies gamma correction to standardize brightness––or luminance–– of images. Generic knowledge about screw features in the form of a deep learning model is then used to visually detects screws. The results are analyzed against common screw location combinations on product components in order to logically reason about possible undetected screws that are also likely to exist. Finally, true negative detections are collected as new training data and the deep learning model is re-trained on these missed detections to improve performance; tailoring and adapting to the environment of the specific disassembly cell.}
}

@misc{wu2018spot,
      title={Spot the Difference by Object Detection},
      author={Junhui Wu and Yun Ye and Yu Chen and Zhi Weng},
      year={2018},
      eprint={1801.01051},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{dwibedi,
  author={Dwibedi, Debidatta and Misra, Ishan and Hebert, Martial},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
  title={Cut, Paste and Learn: Surprisingly Easy Synthesis for Instance Detection},
  year={2017},
  volume={},
  number={},
  pages={1310-1319},
  doi={10.1109/ICCV.2017.146}}

@INPROCEEDINGS{bigbird,
  author={Singh, Arjun and Sha, James and Narayan, Karthik S. and Achim, Tudor and Abbeel, Pieter},
  booktitle={2014 IEEE International Conference on Robotics and Automation (ICRA)},
  title={BigBIRD: A large-scale 3D database of object instances},
  year={2014},
  volume={},
  number={},
  pages={509-516},
  doi={10.1109/ICRA.2014.6906903}}

@article{DBLP:journals/corr/abs-1809-10790,
  author    = {Jonathan Tremblay and
               Thang To and
               Balakumar Sundaralingam and
               Yu Xiang and
               Dieter Fox and
               Stan Birchfield},
  title     = {Deep Object Pose Estimation for Semantic Robotic Grasping of Household
               Objects},
  journal   = {CoRR},
  volume    = {abs/1809.10790},
  year      = {2018},
  url       = {http://arxiv.org/abs/1809.10790},
  archivePrefix = {arXiv},
  eprint    = {1809.10790},
  timestamp = {Fri, 05 Oct 2018 11:34:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1809-10790.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{photo2,
  author={Gupta, Ankush and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title={Synthetic Data for Text Localisation in Natural Images},
  year={2016},
  volume={},
  number={},
  pages={2315-2324},
  doi={10.1109/CVPR.2016.254}}

@InProceedings{real_background1,
author="Hinterstoisser, Stefan
and Lepetit, Vincent
and Wohlhart, Paul
and Konolige, Kurt",
editor="Leal-Taix{\'e}, Laura
and Roth, Stefan",
title="On Pre-trained Image Features and Synthetic Images for Deep Learning",
booktitle="Computer Vision -- ECCV 2018 Workshops",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="682--697",
abstract="Deep Learning methods usually require huge amounts of training data to perform at their full potential, and often require expensive manual labeling. Using synthetic images is therefore very attractive to train object detectors, as the labeling comes for free, and several approaches have been proposed to combine synthetic and real images for training. In this paper, we evaluate if `freezing' the layers responsible for feature extraction to generic layers pre-trained on real images, and training only the remaining layers with plain OpenGL rendering may allow for training with synthetic images only. Our experiments with very recent deep architectures for object recognition (Faster-RCNN, R-FCN, Mask-RCNN) and image feature extractors (InceptionResnet and Resnet) show this simple approach performs surprisingly well.",
isbn="978-3-030-11009-3"
}

@article{real_background2,
  author    = {Param S. Rajpura and
               Ravi S. Hegde and
               Hristo Bojinov},
  title     = {Object Detection Using Deep CNNs Trained on Synthetic Images},
  journal   = {CoRR},
  volume    = {abs/1706.06782},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.06782},
  archivePrefix = {arXiv},
  eprint    = {1706.06782},
  timestamp = {Mon, 13 Aug 2018 16:46:29 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/RajpuraHB17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{real_background3,
  author={Tremblay, Jonathan and Prakash, Aayush and Acuna, David and Brophy, Mark and Jampani, Varun and Anil, Cem and To, Thang and Cameracci, Eric and Boochoon, Shaad and Birchfield, Stan},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  title={Training Deep Networks with Synthetic Data: Bridging the Reality Gap by Domain Randomization},
  year={2018},
  volume={},
  number={},
  pages={1082-10828},
  doi={10.1109/CVPRW.2018.00143}
}

@techreport{WahCUB_200_2011,
	Title = {{The Caltech-UCSD Birds-200-2011 Dataset}},
	Author = {Wah, C. and Branson, S. and Welinder, P. and Perona, P. and Belongie, S.},
	Year = {2011},
	Institution = {California Institute of Technology},
	Number = {CNS-TR-2011-001}
}

@inproceedings{mahendran14understanding,
    Author    = {A. Vedaldi and
                 S. Mahendran and
                 S. Tsogkas and
                 S. Maji and
                 B. Girshick and
                 J. Kannala and
                 E. Rahtu and
                 I. Kokkinos and
                 M. B. Blaschko and
                 D. Weiss and
                 B. Taskar and
                 K. Simonyan and
                 N. Saphra and
                 S. Mohamed},
    Title     = {Understanding Objects in Detail with Fine-grained Attributes},
    Booktitle = {Proceedings of the {IEEE} Conf.
                 on Computer Vision and Pattern Recognition ({CVPR})},
    Year      = {2014}
}

@article{queue1,
 ISSN = {01621459},
 URL = {http://www.jstor.org/stable/27590517},
 abstract = {A call center is a service network in which agents provide telephone-based services. Customers who seek these services are delayed in tele-queues. This article summarizes an analysis of a unique record of call center operations. The data comprise a complete operational history of a small banking call center, call by call, over a full year. Taking the perspective of queueing theory, we decompose the service process into three fundamental components: arrivals, customer patience, and service durations. Each component involves different basic mathematical structures and requires a different style of statistical analysis. Some of the key empirical results are sketched, along with descriptions of the varied techniques required. Several statistical techniques are developed for analysis of the basic components. One of these techniques is a test that a point process is a Poisson process. Another involves estimation of the mean function in a nonparametric regression with lognormal errors. A new graphical technique is introduced for nonparametric hazard rate estimation with censored data. Models are developed and implemented for forecasting of Poisson arrival rates. Finally, the article surveys how the characteristics deduced from the statistical analyses form the building blocks for theoretically interesting and practically useful mathematical models for call center operations.},
 author = {Lawrence Brown and Noah Gans and Avishai Mandelbaum and Anat Sakov and Haipeng Shen and Sergey Zeltyn and Linda Zhao},
 journal = {Journal of the American Statistical Association},
 number = {469},
 pages = {36--50},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Statistical Analysis of a Telephone Call Center: A Queueing-Science Perspective},
 volume = {100},
 year = {2005}
}

@article{queue2,
  title={Call center service times are lognormal: a Fokker--Planck description},
  author={Gualandi, Stefano and Toscani, Giuseppe},
  journal={Mathematical Models and Methods in Applied Sciences},
  volume={28},
  number={08},
  pages={1513--1527},
  year={2018},
  publisher={World Scientific}
}

@ARTICLE{scipy,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}

@article{dawson1988fitting,
  title={Fitting the ex-Gaussian equation to reaction time distributions},
  author={Dawson, Michael RW},
  journal={Behavior Research Methods, Instruments, \& Computers},
  volume={20},
  number={1},
  pages={54--57},
  year={1988},
  publisher={Springer}
}

@article{patience,
title = {The tolerable waiting time: A generalized Pareto distribution model with empirical investigation},
journal = {Computers \& Industrial Engineering},
volume = {137},
pages = {106019},
year = {2019},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2019.106019},
url = {https://www.sciencedirect.com/science/article/pii/S0360835219304772},
author = {Hui Xiong and Lu Ma and Mengxi Ning and Xu Zhao and Jinxian Weng}
}

@article{kendall,
 ISSN = {00034851},
 URL = {http://www.jstor.org/stable/2236285},
 abstract = {The stochastic processes which occur in the theory of queues are in general not Markovian and special methods are required for their analysis. In many cases the problem can be greatly simplified by restricting attention to an imbedded Markov chain. In this paper some recent work on single-server queues is first reviewed from this standpoint, and the method is then applied to the analysis of the following many-server queuing-system: Input: the inter-arrival times are independently and identically distributed in an arbitrary manner. Queue-discipline: "first come, first served." Service-mechanism: a general number, s, of servers; negative-exponential service-times. If Q is the number of people waiting at an instant just preceding the arrival of a new customer, and if w is the waiting time of an arbitrary customer, then it will be shown that the equilibrium distribution of Q is a geometric series mixed with a concentration at Q = 0 and that the equilibrium distribution of w is a negative-exponential distribution mixed with a concentration at w = 0. (In the particular case of a single server this property of the waiting-time distribution was first discovered by W. L. Smith.) The paper concludes with detailed formulae and numerical results for the following particular cases: Numbers of servers: s = 1, 2 and 3. Types of input: (i) Poissonian and (ii) regular.},
 author = {David G. Kendall},
 journal = {The Annals of Mathematical Statistics},
 number = {3},
 pages = {338--354},
 publisher = {Institute of Mathematical Statistics},
 title = {Stochastic Processes Occurring in the Theory of Queues and their Analysis by the Method of the Imbedded Markov Chain},
 urldate = {2022-04-29},
 volume = {24},
 year = {1953}
}

@article{mmn_formula,
author = {Sundari, S.Maragatha and Srinivasan, Santhanagopalan},
year = {2011},
month = {01},
pages = {},
title = {M/M/C queueing model for waiting time of customers in bank sectors},
volume = {1},
journal = {International Journal of Mathematical Sciences \& Applications}
}

@CONFERENCE{ImageNet_VSS09,
        AUTHOR = {Deng, J. and Li, K. and Do, M. and Su, H. and Fei-Fei, L.},
        TITLE = {{Construction and Analysis of a Large Scale Image Ontology}},
        ORGANIZATION = {Vision Sciences Society},
        YEAR = {2009},
        BIBSOURCE = "http://www.image-net.org/papers/ImageNet_VSS2009.bib"}

@inproceedings{KrauseStarkDengFei-Fei_3DRR2013,
  title = {3D Object Representations for Fine-Grained Categorization},
  booktitle = {4th International IEEE Workshop on  3D Representation and Recognition (3dRR-13)},
  year = {2013},
  address = {Sydney, Australia},
  author = {Jonathan Krause and Michael Stark and Jia Deng and Li Fei-Fei}
}

@inproceedings{collaboration,
author = {Johnson, Steven and Gibson, Madeleine and Mutlu, Bilge},
title = {Handheld or Handsfree? Remote Collaboration via Lightweight Head-Mounted Displays and Handheld Devices},
year = {2015},
isbn = {9781450329224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2675133.2675176},
doi = {10.1145/2675133.2675176},
abstract = {Emerging wearable and mobile communication technologies, such as lightweight head-mounted
displays (HMDs) and handheld devices, promise support for everyday remote collaboration.
Despite their potential for widespread use, their effectiveness as collaborative tools
is unknown, particularly in physical tasks involving mobility. To better understand
their impact on collaborative behaviors, perceptions, and performance, we conducted
a two-by-two (technology type: HMD vs. tablet computer; task setting: static vs. dynamic)
between-subjects study where participants (n=66) remotely collaborated as ``helper'
and ``worker' pairs in the construction of a physical object. Our results showed that,
in the dynamic task, HMD use enabled helpers to offer more frequent directing commands
and more proactive assistance, resulting in marginally faster task completion. In
the static task, while tablet use helped convey subtle visual information, helpers
and workers had conflicting perceptions of how the two technologies contributed to
their success. Our findings offer strong design and research implications, underlining
the importance of a consistent view of the shared workspace and the differential support
collaborators with different roles receive from technologies.},
booktitle = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work and Social Computing},
pages = {1825–1836},
numpages = {12},
keywords = {tablet computers, computer-supported cooperative work, head-mounted displays (hmds), videoconferencing, remote collaboration, wearable computing, handheld devices},
location = {Vancouver, BC, Canada},
series = {CSCW '15}
}

@inproceedings{robotic_arm,
author = {Lafreniere, Benjamin and Grossman, Tovi and Anderson, Fraser and Matejka, Justin and Kerrick, Heather and Nagy, Danil and Vasey, Lauren and Atherton, Evan and Beirne, Nicholas and Coelho, Marcelo H. and Cote, Nicholas and Li, Steven and Nogueira, Andy and Nguyen, Long and Schwinn, Tobias and Stoddart, James and Thomasson, David and Wang, Ray and White, Thomas and Benjamin, David and Conti, Maurice and Menges, Achim and Fitzmaurice, George},
title = {Crowdsourced Fabrication},
year = {2016},
isbn = {9781450341899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2984511.2984553},
doi = {10.1145/2984511.2984553},
abstract = {In recent years, extensive research in the HCI literature has explored interactive
techniques for digital fabrication. However, little attention in this body of work
has examined how to involve and guide human workers in fabricating larger-scale structures.
We propose a novel model of crowdsourced fabrication, in which a large number of workers
and volunteers are guided through the process of building a pre-designed structure.
The process is facilitated by an intelligent construction space capable of guiding
individual workers and coordinating the overall build process. More specifically,
we explore the use of smartwatches, indoor location sensing, and instrumented construction
materials to provide real-time guidance to workers, coordinated by a foreman engine
that manages the overall build process. We report on a three day deployment of our
system to construct a 12-tall bamboo pavilion with assistance from more than one hundred
volunteer workers, and reflect on observations and feedback collected during the exhibit.},
booktitle = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
pages = {15–28},
numpages = {14},
keywords = {crowdsourcing, fabrication, iot, wearables},
location = {Tokyo, Japan},
series = {UIST '16}
}

@InProceedings{smartwatch,
author="Aehnelt, Mario
and Urban, Bodo",
editor="Nah, Fiona Fui-Hoon",
title="Follow-Me: Smartwatch Assistance on the Shop Floor",
booktitle="HCI in Business",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="279--287",
abstract="The growing complexity of manufacturing calls for new approaches to support the human workforce with situation-aware information and tools which in consequence ease the process of understanding and applying work related knowledge. With this paper we introduce a theoretical model for a systematic information transfer between assistance system and worker. It defines assistance objectives and reviews the role of artifacts during the assistance process focusing on the cognitive aspects of work. Our approach was implemented using smartwatches for application in industrial assembly environments extending the Plant@Hand manufacturing performance support system.",
isbn="978-3-319-07293-7"
}

@inproceedings{smartwatch2,
author = {Bader, Sebastian and Aehnelt, Mario},
title = {Tracking Assembly Processes and Providing Assistance in Smart Factories},
year = {2014},
isbn = {9789897580154},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0004822701610168},
doi = {10.5220/0004822701610168},
abstract = {Tracking assembly processes is a necessary prerequisite to provide assistance in smart
factories. In this paper, we show how to track the construction of complex components.
For this we employ formal task models as background knowledge and simple sensors like
RFIDs. The background knowledge is converted into a probabilistic model that actually
tracks the process. As a result, we are able to provide assistance in smart factories.
We discuss the performance of the approach, as well as potential applications.},
booktitle = {Proceedings of the 6th International Conference on Agents and Artificial Intelligence - Volume 1},
pages = {161–168},
numpages = {8},
keywords = {Assembly Tracking, Assistance, Smart Factory},
location = {ESEO, Angers, Loire Valley, France},
series = {ICAART 2014}
}

@inproceedings{kinect,
author = {Gupta, Ankit and Fox, Dieter and Curless, Brian and Cohen, Michael},
title = {DuploTrack: A Real-Time System for Authoring and Guiding Duplo Block Assembly},
year = {2012},
isbn = {9781450315807},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2380116.2380167},
doi = {10.1145/2380116.2380167},
abstract = {We demonstrate a realtime system which infers and tracks the assembly process of a
snap-together block model using a Kinect® sensor. The inference enables us to build
a virtual replica of the model at every step. Tracking enables us to provide context
specific visual feedback on a screen by augmenting the rendered virtual model aligned
with the physical model. The system allows users to author a new model and uses the
inferred assembly process to guide its recreation by others. We propose a novel way
of assembly guidance where the next block to be added is rendered in blinking mode
with the tracked virtual model on screen. The system is also able to detect any mistakes
made and helps correct them by providing appropriate feedback. We focus on assemblies
of Duplo® blocks.We discuss the shortcomings of existing methods of guidance - static
figures or recorded videos - and demonstrate how our method avoids those shortcomings.
We also report on a user study to compare our system with standard figure-based guidance
methods found in user manuals. The results of the user study suggest that our method
is able to aid users' structural perception of the model better, leads to fewer assembly
errors, and reduces model construction time.},
booktitle = {Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology},
pages = {389–402},
numpages = {14},
keywords = {assembly tasks, augmented reality, depth camera, active visual feedback, tracking, virtual reality},
location = {Cambridge, Massachusetts, USA},
series = {UIST '12}
}

@InProceedings{sensors,
author="Antifakos, Stavros
and Michahelles, Florian
and Schiele, Bernt",
editor="Borriello, Gaetano
and Holmquist, Lars Erik",
title="Proactive Instructions for Furniture Assembly",
booktitle="UbiComp 2002: Ubiquitous Computing",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="351--360",
abstract="Tennenhouse [1] coined the term proactive computing where humans get out of the interaction loop and may be serviced specifically according to their needs and current situation. In this paper we propose a framework for proactive guidance which aims to overcome limitations of today's printed instructions. By attaching computing devices and multiple sensors onto different parts of the assembly the system can recognize the actions of the user and determine the current state of the assembly. The system can suggest the next most appropriate action at any point in time. In an experimental case study with the IKEA PAX wardrobe we show the feasibility of the proposed approach. At the end important issues are discussed and future directions are outlined.",
isbn="978-3-540-45809-8"
}

@InProceedings{webuild,
author = {Fraser, C. Ailie and Grossman, Tovi and Fitzmaurice, George},
title = {WeBuild: Automatically Distributing Assembly Tasks Among Collocated Workers to Improve Coordination},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026036},
abstract = {Physical construction and assembly tasks are often carried out by groups of collocated
workers, and they can be difficult to coordinate. Group members must spend time deciding
how to split up the task, how to assign subtasks to each other, and in what order
subtasks should be completed. Informed by an observational study examining group coordination
challenges, we built a task distribution system called WeBuild. Our custom algorithm
dynamically assigns subtasks to workers in a group, taking into account factors such
as the dependencies between subtasks and the skills of each group member. Each worker
views personalized step-by-step instructions on a mobile phone, while a dashboard
visualizes the entire process. An initial study found that WeBuild reduced the start-up
time needed to coordinate and begin a task, and provides direction for future research
to build on toward improving group efficiency and coordination for complex tasks.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1817–1830},
numpages = {14}
}

@article{synthetic,
  author    = {Stefan Hinterstoisser and
               Olivier Pauly and
               Hauke Heibel and
               Martina Marek and
               Martin Bokeloh},
  title     = {An Annotation Saved is an Annotation Earned: Using Fully Synthetic
               Training for Object Instance Detection},
  journal   = {CoRR},
  volume    = {abs/1902.09967},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.09967},
  archivePrefix = {arXiv},
  eprint    = {1902.09967},
  timestamp = {Tue, 21 May 2019 18:03:39 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-09967.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{shaping,
author = {Hu, Wenlu and Amos, Brandon and Chen, Zhuo and Ha, Kiryong and Richter, Wolfgang and Pillai, Padmanabhan and Gilbert, Benjamin and Harkes, Jan and Satyanarayanan, Mahadev},
title = {The Case for Offload Shaping},
year = {2015},
isbn = {9781450333917},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2699343.2699351},
doi = {10.1145/2699343.2699351},
abstract = {When offloading computation from a mobile device, we show that it can pay to perform
additional on-device work in order to reduce the offloading workload. We call this
offload shaping, and demonstrate its application at many different levels of abstraction
using a variety of techniques. We show that offload shaping can produce significant
reduction in resource demand, with little loss of application-level fidelity.},
booktitle = {Proceedings of the 16th International Workshop on Mobile Computing Systems and Applications},
pages = {51–56},
numpages = {6},
keywords = {mobile computing, cloud computing, energy-efficient computing, wireless networks, cyber foraging, wearable computing, early discard, wifi, google glass, cloud offload, cloudlet},
location = {Santa Fe, New Mexico, USA},
series = {HotMobile '15}
}

@article{coco,
  author    = {Tsung{-}Yi Lin and
               Michael Maire and
               Serge J. Belongie and
               Lubomir D. Bourdev and
               Ross B. Girshick and
               James Hays and
               Pietro Perona and
               Deva Ramanan and
               Piotr Doll{\'{a}}r and
               C. Lawrence Zitnick},
  title     = {Microsoft {COCO:} Common Objects in Context},
  journal   = {CoRR},
  volume    = {abs/1405.0312},
  year      = {2014},
  url       = {http://arxiv.org/abs/1405.0312},
  archivePrefix = {arXiv},
  eprint    = {1405.0312},
  timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LinMBHPRDZ14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{latency,
    doi = {10.1371/journal.pone.0248690},
    author = {Olguín Muñoz, Manuel AND Klatzky, Roberta AND Wang, Junjue AND Pillai, Padmanabhan AND Satyanarayanan, Mahadev AND Gross, James},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Impact of delayed response on wearable cognitive assistance},
    year = {2021},
    month = {03},
    volume = {16},
    url = {https://doi.org/10.1371/journal.pone.0248690},
    pages = {1-25},
    abstract = {Wearable cognitive assistants (WCA) are anticipated to become a widely-used application class, in conjunction with emerging network infrastructures like 5G that incorporate edge computing capabilities. While prototypical studies of such applications exist today, the relationship between infrastructure service provisioning and its implication for WCA usability is largely unexplored despite the relevance that these applications have for future networks. This paper presents an experimental study assessing how WCA users react to varying end-to-end delays induced by the application pipeline or infrastructure. Participants interacted directly with an instrumented task-guidance WCA as delays were introduced into the system in a controllable fashion. System and task state were tracked in real time, and biometric data from wearable sensors on the participants were recorded. Our results show that periods of extended system delay cause users to correspondingly (and substantially) slow down in their guided task execution, an effect that persists for a time after the system returns to a more responsive state. Furthermore, the slow-down in task execution is correlated with a personality trait, neuroticism, associated with intolerance for time delays. We show that our results implicate impaired cognitive planning, as contrasted with resource depletion or emotional arousal, as the reason for slowed user task executions under system delay. The findings have several implications for the design and operation of WCA applications as well as computational and communication infrastructure, and additionally for the development of performance analysis tools for WCA.},
    number = {3}
}

@inproceedings{ha2014,
author = {Ha, Kiryong and Chen, Zhuo and Hu, Wenlu and Richter, Wolfgang and Pillai, Padmanabhan and Satyanarayanan, Mahadev},
title = {Towards Wearable Cognitive Assistance},
year = {2014},
isbn = {9781450327930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2594368.2594383},
doi = {10.1145/2594368.2594383},
abstract = {We describe the architecture and prototype implementation of an assistive system based on Google Glass devices for users in cognitive decline. It combines the first-person image capture and sensing capabilities of Glass with remote processing to perform real-time scene interpretation. The system architecture is multi-tiered. It offers tight end-to-end latency bounds on compute-intensive operations, while addressing concerns such as limited battery capacity and limited processing capability of wearable devices. The system gracefully degrades services in the face of network failures and unavailability of distant architectural tiers.},
booktitle = {Proceedings of the 12th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {68–81},
numpages = {14},
keywords = {cloudlet, wearable computing, cyber foraging, cloud offload, google glass, cloud computing, virtual machine, mobile computing},
location = {Bretton Woods, New Hampshire, USA},
series = {MobiSys '14}
}

@inproceedings{chen2017,
author = {Chen, Zhuo and Hu, Wenlu and Wang, Junjue and Zhao, Siyan and Amos, Brandon and Wu, Guanhang and Ha, Kiryong and Elgazzar, Khalid and Pillai, Padmanabhan and Klatzky, Roberta and Siewiorek, Daniel and Satyanarayanan, Mahadev},
title = {An Empirical Study of Latency in an Emerging Class of Edge Computing Applications for Wearable Cognitive Assistance},
year = {2017},
isbn = {9781450350877},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132211.3134458},
doi = {10.1145/3132211.3134458},
abstract = {An emerging class of interactive wearable cognitive assistance applications is poised to become one of the key demonstrators of edge computing infrastructure. In this paper, we design seven such applications and evaluate their performance in terms of latency across a range of edge computing configurations, mobile hardware, and wireless networks, including 4G LTE. We also devise a novel multi-algorithm approach that leverages temporal locality to reduce end-to-end latency by 60% to 70%, without sacrificing accuracy. Finally, we derive target latencies for our applications, and show that edge computing is crucial to meeting these targets.},
booktitle = {Proceedings of the Second ACM/IEEE Symposium on Edge Computing},
articleno = {14},
numpages = {14},
keywords = {cloud computing, cloudlet, hololens, edge computing, mobile computing, smart glass, augmented reality},
location = {San Jose, California},
series = {SEC '17}
}

@inproceedings{wang2019,
author = {Wang, Junjue and Feng, Ziqiang and George, Shilpa and Iyengar, Roger and Pillai, Padmanabhan and Satyanarayanan, Mahadev},
title = {Towards Scalable Edge-Native Applications},
year = {2019},
isbn = {9781450367332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318216.3363308},
doi = {10.1145/3318216.3363308},
abstract = {Latency-sensitive edge-native applications may be the key to commercial success of edge infrastructure. However, success in the form of widespread deployment of such applications poses its own challenges. These applications are edge-dependent by definition, and therefore cannot simply fail over to the cloud if the edge is overloaded. In this paper, we propose an adaptation-based strategy to allow scaling up the number of concurrent edge-native applications on a resource-limited cloudlet and wireless network. We demonstrate up to 40% reduction in offered load with minimal impact on latency on a variety of cognitive assistance tasks over non-adaptive approaches. Our approach is able to gracefully degrade and maintain quality of service for a subset of applications in the face of severely loaded conditions.},
booktitle = {Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
pages = {152–165},
numpages = {14},
keywords = {mobile computing, cloudlet, resource management, edge computing, gabriel, wearable cognitive assistance},
location = {Arlington, Virginia},
series = {SEC '19}
}

@article{pham2021ajalon,
author = {Pham, Truong An and Wang, Junjue and Iyengar, Roger and Xiao, Yu and Pillai, Padmanabhan and Klatzky, Roberta and Satyanarayanan, Mahadev},
title = {Ajalon: Simplifying the authoring of wearable cognitive assistants},
journal = {Software: Practice and Experience},
volume = {51},
number = {8},
pages = {1773-1797},
keywords = {artificial intelligence, augmented reality, cloudlets, computer vision, edge computing, Gabriel, machine learning, mobile computing, software productivity, wearables},
doi = {https://doi.org/10.1002/spe.2987},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.2987},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.2987},
year = {2021}
}

@misc{TPOD,
  title = {OpenTPOD},
  howpublished = {\url{https://github.com/cmusatyalab/OpenTPOD}}
}

@misc{workflow,
  title = {OpenWorkflow},
  howpublished = {\url{https://github.com/cmusatyalab/OpenWorkflow}}
}

@misc{lamp,
  title = {Lamp Assistant},
  howpublished = {\url{https://github.com/cmusatyalab/gabriel-ikea}}
}

@misc{sandwich,
  title = {Sandwich Assistant},
  howpublished = {\url{https://github.com/cmusatyalab/gabriel-sandwich}}
}

@misc{lego,
  title = {Lego Assistant},
  howpublished = {\url{https://github.com/cmusatyalab/gabriel-lego}}
}

@inproceedings{frcnn,
 author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
 url = {https://proceedings.neurips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf},
 volume = {28},
 year = {2015}
}

@INPROCEEDINGS{satya14,
  author={Satyanarayanan, Mahadev and Chen, Zhuo and Ha, Kiryong and Hu, Wenlu and Richter, Wolfgang and Pillai, Padmanabhan},
  booktitle={6th International Conference on Mobile Computing, Applications and Services},
  title={Cloudlets: at the leading edge of mobile-cloud convergence},
  year={2014},
  volume={},
  number={},
  pages={1-9},
  doi={10.4108/icst.mobicase.2014.257757}}

@inproceedings{joseph2021open,
  title={Towards Open World Object Detection},
  author={K J Joseph and Salman Khan and Fahad Shahbaz Khan and Vineeth N Balasubramanian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2021)},
  eprint={2103.02603},
  archivePrefix={arXiv},
  year={2021}
}

@misc{gabriel_github,
  title = {The Gabriel framework for wearable cognitive assistance using
  cloudlets},
  howpublished = {\url{https://github.com/cmusatyalab/gabriel}}
}

@article{opencv_library,
    author = {Bradski, G.},
    citeulike-article-id = {2236121},
    journal = {Dr. Dobb's Journal of Software Tools},
    keywords = {bibtex-import},
    posted-at = {2008-01-15 19:21:54},
    priority = {4},
    title = {{The OpenCV Library}},
    year = {2000}
}

@misc{camerax,
  title = {CameraX overview},
  howpublished = {\url{https://developer.android.com/training/camerax}}
}

@misc{gabriel_server,
  title = {Gabriel Server},
  howpublished = {\url{https://pypi.org/project/gabriel-server/}}
}

@misc{gabriel_python_client,
  title = {Gabriel Python Client},
  howpublished = {\url{https://pypi.org/project/gabriel-client/}}
}

@misc{gabriel_android_client,
  title = {Gabriel Android Client},
  howpublished = {\url{https://repo1.maven.org/maven2/edu/cmu/cs/gabriel/}}
}

@misc{zmq,
  title = {ZeroMQ},
  howpublished = {\url{https://zeromq.org/}}
}

@article{Satya2017,
 author = "Mahadev Satyanarayanan",
 title = "{The Emergence of Edge Computing}",
 journal = "{IEEE Computer}",
 volume = "50",
 number = "1",
 year = "2017"
}

@conference{visapp19,
author={Julien Miranda. and Stanislas Larnier. and Ariane Herbulot. and Michel Devy.},
title={UAV-based Inspection of Airplane Exterior Screws with Computer Vision},
booktitle={Proceedings of the 14th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications - Volume 4: VISAPP,},
year={2019},
pages={421-427},
publisher={SciTePress},
organization={INSTICC},
doi={10.5220/0007571304210427},
isbn={978-989-758-354-4},
issn={2184-4321},
}

@article{FOO2021666,
title = {Screw detection for disassembly of electronic waste using reasoning and re-training of a deep learning model},
journal = {Procedia CIRP},
volume = {98},
pages = {666-671},
year = {2021},
note = {The 28th CIRP Conference on Life Cycle Engineering, March 10 – 12, 2021, Jaipur, India},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.01.172},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121002031},
author = {Gwendolyn Foo and Sami Kara and Maurice Pagnucco},
keywords = {disassembly automation, computer vision, screw detection, ontology, logical reasoning, LCD monitors},
abstract = {Growing populations, increasing standards of living, and reliance on advancing technologies are resulting in an emerging abundance of electronic waste. Automating disassembly of these electronic products is a vital part of improving end-of-life product treatment where hazardous chemicals and materials are present. Furthermore, non-destructive disassembly is ideal to preserve the embodied energy in components from manufacturing. This requires the removal, and hence detection, of fasteners like screws in a disassembly environment. Crosshead screws are a common fastener type used in LCD monitors. This paper proposes a method of screw detection for disassembly and presents results of detection of crosshead screws on components of various models of LCD monitors in a disassembly cell. The system first applies gamma correction to standardize brightness––or luminance–– of images. Generic knowledge about screw features in the form of a deep learning model is then used to visually detects screws. The results are analyzed against common screw location combinations on product components in order to logically reason about possible undetected screws that are also likely to exist. Finally, true negative detections are collected as new training data and the deep learning model is re-trained on these missed detections to improve performance; tailoring and adapting to the environment of the specific disassembly cell.}
}

@misc{wu2018spot,
      title={Spot the Difference by Object Detection},
      author={Junhui Wu and Yun Ye and Yu Chen and Zhi Weng},
      year={2018},
      eprint={1801.01051},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{dwibedi,
  author={Dwibedi, Debidatta and Misra, Ishan and Hebert, Martial},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
  title={Cut, Paste and Learn: Surprisingly Easy Synthesis for Instance Detection},
  year={2017},
  volume={},
  number={},
  pages={1310-1319},
  doi={10.1109/ICCV.2017.146}}

@INPROCEEDINGS{bigbird,
  author={Singh, Arjun and Sha, James and Narayan, Karthik S. and Achim, Tudor and Abbeel, Pieter},
  booktitle={2014 IEEE International Conference on Robotics and Automation (ICRA)},
  title={BigBIRD: A large-scale 3D database of object instances},
  year={2014},
  volume={},
  number={},
  pages={509-516},
  doi={10.1109/ICRA.2014.6906903}}

@article{DBLP:journals/corr/abs-1809-10790,
  author    = {Jonathan Tremblay and
               Thang To and
               Balakumar Sundaralingam and
               Yu Xiang and
               Dieter Fox and
               Stan Birchfield},
  title     = {Deep Object Pose Estimation for Semantic Robotic Grasping of Household
               Objects},
  journal   = {CoRR},
  volume    = {abs/1809.10790},
  year      = {2018},
  url       = {http://arxiv.org/abs/1809.10790},
  archivePrefix = {arXiv},
  eprint    = {1809.10790},
  timestamp = {Fri, 05 Oct 2018 11:34:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1809-10790.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{photo2,
  author={Gupta, Ankush and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title={Synthetic Data for Text Localisation in Natural Images},
  year={2016},
  volume={},
  number={},
  pages={2315-2324},
  doi={10.1109/CVPR.2016.254}}

@InProceedings{real_background1,
author="Hinterstoisser, Stefan
and Lepetit, Vincent
and Wohlhart, Paul
and Konolige, Kurt",
editor="Leal-Taix{\'e}, Laura
and Roth, Stefan",
title="On Pre-trained Image Features and Synthetic Images for Deep Learning",
booktitle="Computer Vision -- ECCV 2018 Workshops",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="682--697",
abstract="Deep Learning methods usually require huge amounts of training data to perform at their full potential, and often require expensive manual labeling. Using synthetic images is therefore very attractive to train object detectors, as the labeling comes for free, and several approaches have been proposed to combine synthetic and real images for training. In this paper, we evaluate if `freezing' the layers responsible for feature extraction to generic layers pre-trained on real images, and training only the remaining layers with plain OpenGL rendering may allow for training with synthetic images only. Our experiments with very recent deep architectures for object recognition (Faster-RCNN, R-FCN, Mask-RCNN) and image feature extractors (InceptionResnet and Resnet) show this simple approach performs surprisingly well.",
isbn="978-3-030-11009-3"
}

@article{real_background2,
  author    = {Param S. Rajpura and
               Ravi S. Hegde and
               Hristo Bojinov},
  title     = {Object Detection Using Deep CNNs Trained on Synthetic Images},
  journal   = {CoRR},
  volume    = {abs/1706.06782},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.06782},
  archivePrefix = {arXiv},
  eprint    = {1706.06782},
  timestamp = {Mon, 13 Aug 2018 16:46:29 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/RajpuraHB17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{real_background3,
  author={Tremblay, Jonathan and Prakash, Aayush and Acuna, David and Brophy, Mark and Jampani, Varun and Anil, Cem and To, Thang and Cameracci, Eric and Boochoon, Shaad and Birchfield, Stan},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  title={Training Deep Networks with Synthetic Data: Bridging the Reality Gap by Domain Randomization},
  year={2018},
  volume={},
  number={},
  pages={1082-10828},
  doi={10.1109/CVPRW.2018.00143}
}

@Inbook{Simon1991,
author="Simon, Herbert A.",
title="The Architecture of Complexity",
bookTitle="Facets of Systems Science",
year="1991",
publisher="Springer US",
address="Boston, MA",
pages="457--476",
abstract="A number of proposals have been advanced in recent years for the development of ``general systems theory'' which, abstracting from properties peculiar to physical, biological, or social systems, would be applicable to all of them. We might well feel that, while the goal is laudable, systems of such diverse kinds could hardly be expected to have any nontrivial properties in common. Metaphor and analogy can be helpful, or they can be misleading. All depends on whether the similarities the metaphor captures are significant or superficial.",
isbn="978-1-4899-0718-9",
doi="10.1007/978-1-4899-0718-9_31",
url="https://doi.org/10.1007/978-1-4899-0718-9_31"
}

@misc{xin,
  title = {“A machine learning model is only as good as the data it is fed”},
  author={Gabriela Motroc},
  howpublished = {\url{https://jaxenter.com/apache-spark-machine-learning-interview-143122.html}}
}

@misc{gebru2017finegrained,
      title={Fine-Grained Car Detection for Visual Census Estimation},
      author={Timnit Gebru and Jonathan Krause and Yilun Wang and Duyun Chen and Jia Deng and Li Fei-Fei},
      year={2017},
      eprint={1709.02480},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{stirling_github,
  title = {Wearable Cognitive Assistant for Stirling Engine},
  howpublished = {\url{https://github.com/cmusatyalab/gabriel-stirling-engine}}
}

@misc{stirling_youtube,
  title = {Stirling Engine Disassembly Assistant - YouTube},
  howpublished = {\url{https://youtu.be/tU8jyDh_DGs}}
}

@misc{ikea_youtube,
  title = {Wearable Cognitive Assistance for assembly of IKEA Utility Cart, with escalation to a remote expert - YouTube},
  howpublished = {\url{https://youtu.be/yO56SsZZRDg}}
}

@misc{ikea_github,
  title = {Gabriel-based cognitive assistance application for IKEA cart assembly},
  howpublished = {\url{https://github.com/cmusatyalab/gabriel-cart}}
}

@techreport{WahCUB_200_2011,
	Title = {{The Caltech-UCSD Birds-200-2011 Dataset}},
	Author = {Wah, C. and Branson, S. and Welinder, P. and Perona, P. and Belongie, S.},
	Year = {2011},
	Institution = {California Institute of Technology},
	Number = {CNS-TR-2011-001}
}

@inproceedings{mahendran14understanding,
    Author    = {A. Vedaldi and
                 S. Mahendran and
                 S. Tsogkas and
                 S. Maji and
                 B. Girshick and
                 J. Kannala and
                 E. Rahtu and
                 I. Kokkinos and
                 M. B. Blaschko and
                 D. Weiss and
                 B. Taskar and
                 K. Simonyan and
                 N. Saphra and
                 S. Mohamed},
    Title     = {Understanding Objects in Detail with Fine-grained Attributes},
    Booktitle = {Proceedings of the {IEEE} Conf.
                 on Computer Vision and Pattern Recognition ({CVPR})},
    Year      = {2014}
}
